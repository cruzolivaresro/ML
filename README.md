### Apuntes de Machine learning ###

*Bibliograf√≠a*:
**G√©ron, A. (2019). Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow (2nd ed.). O'Reilly Media.**

*Antecedente*:

[Este articulo](https://www.cs.toronto.edu/~hinton/absps/ncfast.pdf) fue un relevo que tuvo deep learning el 2006, debido a que los investigadores en los 90's habian desistido de estas t√©cnicas.

[Aqu√≠ puedes practicar los t√≥picos del libro](https://github.com/ageron/handson-ml2)

[Cursos de Deep Learning en Coursera](https://www.coursera.org/learn/machine-learning/?isNewUser=true#testimonials)

[Documentaci√≥n scikit-learn](https://scikit-learn.org/stable/user_guide.html) 


**Cap√≠tulo 1: Panorama del aprendizaje autom√°tico**

¬øQu√© es y para qu√© usarlo?
Lo importante es que las m√°quinas sean programadas de alguna forma para que aprendan de los datos.

Tres cosas importantes existen en armonia: La experiencia a la que se enfrenta la m√°quina, las tareas que debe realizar la m√°quina y una medida de desempe√±o que oriente el aprendizaje.

Entonces, debemos entenderlo como: **si el desempe√±o en la tarea T, medido por P, mejora con la experiencia E.**

**Filtro spam:** dado una serie de ejemplos de correos spam etiquetados y una serie de ejemplos de correos normales (*ham*), se podr√≠a aprender a etiquetar correos en *spam* o *ham*.

**Training set:** conjunto de datos que el sistema utiliza para aprender, cada registro se le llama **sample**.

*Ejemplo:* La tarea es etiquetar correos **T** dada la experiencia de training set **E** y la medida de desempe√±o **P**.

Una medida de desempe√±o podr√≠a ser la proporci√≥n de correos correctamente etiquetados. Tambi√©n conocida como **Accuracy** o **Precisi√≥n** utilizada para tareas de clasificaci√≥n:

$$
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$

Donde:
- **TP (True Positives)**: Correos spam correctamente clasificados como spam.
- **TN (True Negatives)**: Correos no spam correctamente clasificados como no spam.
- **FP (False Positives)**: Correos no spam incorrectamente clasificados como spam.
- **FN (False Negatives)**: Correos spam incorrectamente clasificados como no spam.

Un valor de **Accuracy** cercano a 1 indica un alto desempe√±o del clasificador.

**Data Mining:** Con t√©cnicas de machine learning podemos cavar en grandes cantidades de datos para encontrar patrones en los datos que aparentemente no son faciles de reconocer en una primera instancia.

*Pasos:*
  - Estudiar el problema.
  - Recopilar datos.
  - Entrenar algoritmo ML.
  - Resultados.
  - Inspeccionar resultados.
  - Entender mejor el problema.
  - Iterar desde el paso 1 si es necesario.

*Recomendaciones de uso:*
  - Cuando los problemas tienen una gran cantidad de reglas.
  - Cuando los problemas son demasiado complejos, ML puede ser una soluci√≥n util.
  - Cuando los entornos son fluctuantes, ML puede adaptarse a nuevos datos.
  - Para obtener conocimiento de problemas complejos y grandes cantidades de datos.

*Ejemplos de aplicaci√≥n:*

  -**Clasificador de im√°genes (CNN)**: Analizar imagenes de productos en una linea de producci√≥n para clasificarlos autom√°ticamente.
  -**Segmentaci√≥n sem√°ntica (CNN)**: Detector de tumores en scaneos cerebrales, cada pixel de la imagen es clasificado.  
  -**Procesamiento de lenguaje natural (RNN, CNN, Transformers)**: Clasificador autom√°tico de nuevos art√≠culos o clasificador de comentarios ofensivos.  
  -**Summarization**: Rama del procesamiento de lenguaje natural para resumir textos.  
  -**Chatbots**: Involucra muchos topicos de PLN incluyendo **entendimiento de lenguaje natural (NLU)** y modulos de pregunta/respuesta.  
  -**Regresi√≥n**: Pron√≥stico de valores. Puedes utilizar m√©tricas pasadas utilizando RNN, CNN o transformers.  
  -**Reconocimiento de voz**: Procesa archivos de audio, es considerado complejo, se utilizan RNN, CNN o transformers.  
  -**Detecci√≥n de anomal√≠as**: Detectar tarjetas de cr√©dito fraudulentas.  
  -**Clustering**: Segmentar clientes basado en sus compras para crear distintas estrategias de marketing.
  -**Reducci√≥n de dimensionalidad**: Representar datos de alta dimension y complejos en un diagrama evidente.  
  -**Sistemas recomendadores**: Recomendar productos a clientes que podr√≠an estar interesados basado en sus compras anteriores.  
  -**Aprendizaje reforzado**: Hacer un bot inteligente para juegos. Modelo en donde el agente escoge maximizar las recompensas a trav√©s del tiempo dado un ambiente espec√≠fico. **AlphaGo**

*Tipos de Machine Learning*:
  - **(Supervised, Unsupervised, Semisupervised, RL)**: Si es que est√°n o no siendo entrenados con supervisi√≥n humana.
  - **(online learning v/s batch learning)**: Si es que pueden o no aprender incrementalmente en el camino.
  - **(instance-based learning v/s model-based learning)**: Cuando se busca comparar nuevos datos con datos conocidos *o* busca detectar patrones en el set de entrenamiento y construir modelos predictivos.
  - Podemos mezclar estos tipos, por ejemplo, un filtro spam que pueda aprender en el camino usando una red neuronal profunda basado en modelo usando samples de spam o ham. *Online, model-based, Supervised*

***

**1. Supervisado**: El set de entrenamiento contiene las soluciones esperadas **(labels)**. Un ejemplo cl√°sico es clasificaci√≥n de spam/ham. Otro ejemplo es predecir el valor de un objetivo como el precio de un auto dado un set de cualidades llamados **predictores**.

Algoritmos relacionados al aprendizaje supervisado:

  - **K-nearest Neighbors**
  - **Linear Regression**
  - **Logistic Regression**
  - **Support vector machines**
  - **Decision Tree and Random Forests**
  - **Neural Networks**

***

**2. NO Supervisado**: El set de entrenamiento no contiene labels, por lo que aprende sin profesor.

Algoritmos relacionados al aprendizaje no supervisado:

  -**Clustering**
  
    K-Means
    DBSCAN
    Hierarchical Cluster Analysis (HCA)
    
  -**Anomaly detection and novelty detection**
  
    One-class SVM
    Isolation forest
    
  -**Visualization and Dimensionality reduction**
  
    Principal Component Analysis (PCA)
    Kernel PCA
    Locally Linear Embedding (LLE)
    t-Distributed Stochastic Neighbor Embedding (t-SNE)
    
  -**Association rule learning**
  
    Apriori
    Eclat

El libro recomienda aplicar reducci√≥n de dimensionalidad al dataset, ya sea de manera supervisada o no, para acelerar la ejecuci√≥n del programa, reducir el uso de memoria y, en algunos casos, mejorar el rendimiento. **Sin embargo**, esto depende del contexto, ya que en ciertas situaciones podr√≠a ser m√°s beneficioso aplicar t√©cnicas de feature engineering. Es importante recordar que reducir la dimensionalidad puede ayudar a disminuir la correlaci√≥n entre variables, pero tambi√©n podr√≠a llevar a la p√©rdida de informaci√≥n relevante.

***

**3. Semisupervisado**: Cuando tienes algunos samples con label y otros no, por temas de econom√≠a. Algunos algoritmos pueden tratar con la falta de datos etiquetados. *(DBN y RBM)*

***

**4. Reinforcement Learning**: El sistema de aprendizaje es un **agente**, el cual puede observar un **ambiente** espec√≠fico, puede seleccionar o realizar **acciones** y recibe **rewards** como retorno o **penalties**. Por lo tanto, debe aprender por s√≠ mismo cu√°l es la mejor estrategia para obtener la mejor recompensa en el tiempo. Una **pol√≠tica** establecer√° cual acci√≥n el agente deber√≠a elegir cuando se le da una situaci√≥n.

*Pasos*:

  - Observar.
  - Seleccionar acci√≥n utilizando una pol√≠tica.
  - Actuar.
  - Obtener reward o penalty.
  - Actualizar la pol√≠tica **(paso de aprendizaje)**.
  - Iterar hasta que una pol√≠tica √≥ptima a sido encontrada.

***

**Batch & Online Learning**: Cuando el sistema puede o no aprender incrementalmente a partir de un flujo de datos entrantes.

**5. Batch**: El sistema es incapaz de aprender incrementalmente, es decir, se entrena utilizando toda la data. Si quieres que aprenda de nuevos datos, es necesario entrenar nuevamente utilizando la data nueva y la antigua. Debemos recordar que entrenar con todo el dataset puede ser costoso en recursos *(CPU, memoria, disco, I/O, network I*O, etc).* 

**6. Online**: El sistema es capaz de aprender incrementalmente, ya sea por instancias secuenciales de agregaci√≥n de datos o en grupos peque√±os **mini-batches**. En este sistema, un modelo es entrenado y lanzado en producci√≥n, pero seguir√° aprendiendo de los nuevos datos que entren al modelo. Debemos recordar que este aprendizaje no es *en vivo*, sino que es incremental, es decir, el aprendizaje de todas formas es offline. Tambi√©n es importante considerar el par√°metro con el que el sistema se adapta a los cambios en los datos llamado **learning rate**. Alto learning rate, tender√° a olvidar la data antigua. Bajo learning rate, aprender√° lento, pero ser√° menos sensitivo al ruido en la nueva data u outliers. Si ves un problema en los resultados, siempre es util chequear la calidad del imput.

***

**Instance v/s model learning**: ¬øC√≥mo se generaliza? En el sentido de que los sistemas ML tratan hacer predicciones y estan deben ser buenas pasa samples que no ha visto antes. Lo fundamental no es tanto las m√©tricas, sino como funciona frente a nuevos samples.

**7. Instance-based learning**: Se utiliza una medida de similaridad entre objetos, por ejemplo, el numero de palabras que tienen en com√∫n. Por lo tanto, para este tipo de aprendizaje, el sistema aprende de memoria y generaliza para objetos comunes mediante una medida de similaridad.

**8. Model-based learning**: Se construye un modelo con el set de entrenamiento y se usa para realizar predicciones. Por ejemplo, si quiero saber si el dinero hace feliz a las personas, descargo datos especificos [Better Life Index](https://data-explorer.oecd.org/vis?tenant=archive&df[ds]=DisseminateArchiveDMZ&df[id]=DF_BLI&df[ag]=OECD) y descargo m√©tricas del [PIB](https://www.imf.org/en/Publications/SPROLLS/world-economic-outlook-databases#sort=%40imfdate%20descending). Uno ambos datos y ordeno por PIB. Se observa que hay un patr√≥n lineal entre ambas variables, entonces decido realizar un modelo de satisfacci√≥n de vida en funci√≥n lineal de PIB. Este paso es selecci√≥n de modelo, es decir, seleccionas un modelo lineal con un solo atributo:

$$
\mathrm{Life\_Satisfaction} = \Theta_0 + \Theta_1 \cdot PIB
$$


El cual es un modelo con dos parametros, donde al manejarlos, podemos representar una funci√≥n lineal que mejor se ajuste al comportamiento de los datos. Para encontrar los mejores parametros, es util utilizar una medida de funcionamiento, por ejemplo, fitness (qu√© tan bueno) o cost (qu√© tan malo) function. Por ejemplo, usualmente se utiliza la funci√≥n de costo que mide la distancia entre las predicciones del modelo y los samples de entrenamiento, con el fin de minimizar esta distancia.

*Pasos*:
  - Encuentras un patr√≥n.
  - Estableces un modelo para una variable espec√≠fica.
  - Alimentas el modelo con entrenamiento.
  - Encuentras los mejores parametros de ajuste.
  - Realizas predicciones.

Por ejemplo, podr√≠a predecir la satisfacci√≥n de vida, dado los datos de PIB de un pa√≠s. Siempre debemos estar atento a los sesgos que podr√≠amos imponer al utilizar modelos de esta manera.
Si el modelo no funcionace bien, entonces ser√≠a **√∫til agregar m√°s predictores** *(employment rate, health, air pollution, etc.)* o **encontrar una mejor fuente de datos** o **seleccionar un mejor modelo** *(e.g., a Polynomial
Regression model)*.

***

*En general:*
  - Estudiamos los datos.
  - Seleccionamos un modelo.
  - Lo entrenas con datos de entrenamiento con la medida especifica.
  - Aplicas el modelo para realizar predicciones con la esperanza de que generalice bien.

***
**Sampling Bias**: Si tomas una muestra demasiado peque√±a de la poblaci√≥n, los resultados pueden estar influenciados por el azar y no reflejar realmente las tendencias generales. Aumentar el tama√±o de la muestra no garantiza que sea representativa si el m√©todo de selecci√≥n est√° sesgado.

**Ejemplo**: Si preguntas a solo 5 clientes de Studio Face qu√© servicio prefieren, podr√≠as obtener respuestas que no reflejan las preferencias del total de clientes.

**Ejemplo**: Si solo encuestas a clientes que visitan el sal√≥n los martes, podr√≠as obtener resultados sesgados y no reflejar las preferencias de quienes van otros d√≠as.

***

**Overfitting**: cuando un modelo es demasiado complejo en relacion con la cantidad y calidad de los datos de entrenamiento, es decir, el modelo aprende muy bien los detalles y el ruido de los datos de entrenamiento. Esto generaliza mal.

  -*Demasiado complejo*: Demasiados parametros o usa t√©cnicas avanzadas que lo vuelven complejo.
  
  -*Poco training set*: Si el conjunto de datos peque√±o, entonces el modelo puede memorizar datos en lugar de aprender patrones.
  
  -*Datos con mucho ruido*: Errores o valores at√≠picos, aprender√° de patrones incorrectos.

**Regularizaci√≥n**: Hacer modelos simples y reducir el riesgo de sobreajuste.

**Grados de libertad en estadistica**: indica cuantos valores pueden variar libremente en un conjunto de datos despues de aplicar restricciones. Ejemplo: tengo 5 variables que en promedio resulta 10. Puedo mover todas las variables, pero me restringo a que la ultima variable ser√° constante. Por lo tanto, los grados de libertad son 4, debido a que la ultima variable est√° restringida a tener valores.

**Grados de libertad en ML**: indica cuantos parametros del modelo pueden ajustarse libremente para mejorar el ajuste de los datos. EJ: RL simple, hay 2 parametros ajustables.

*En ambos casos, los grados de libertad representan la cantidad de valores o par√°metros que pueden cambiar libremente:*

  -En estad√≠stica inferencial, se usan para calcular pruebas como t-student, Chi-cuadrado o ANOVA.
  
  -En machine learning, se usan para describir la flexibilidad del modelo y su capacidad de ajustarse a los datos.

***

**Debemos evaluar y afinar modelo si es necesario para asegurar mejores predicciones**

Si el error de entrenamiento es bajo, pero la generalizaci√≥n de errores es alta, significa que el modelo esta sobreajustando los datos de entrenamiento.

**Sobreajuste al set test** o **data lakeable (fuga de datos) del set test**: Se sobreajusta el modelo para el conjunto test especifico. En un flujo de trabajo adecuado, el conjunto de prueba solo debe usarse una vez, al final del proceso, para evaluar el modelo final. Sin embargo, si mides el error en el test set varias veces y ajustas el modelo bas√°ndote en estos resultados, el modelo comienza a aprender las caracter√≠sticas espec√≠ficas del test set, en lugar de aprender una representaci√≥n general de los datos.

**Holdout validation**: se reserva una parte del conjunto de entrenamiento para evaluar varios modelos candidatos y seleccionar el mejor. El conjunto ser√° el **validation set**.

En lugar de usar el test set para ajustar el modelo, divides el conjunto de datos en tres partes:

1. Training Set (conjunto de entrenamiento): Se usa para entrenar el modelo.
  
2. Validation Set (conjunto de validaci√≥n o dev set): Se reserva una parte del training set (por ejemplo, el 20-30%) para evaluar diferentes modelos y ajustar los hiperpar√°metros. Permite comparar el rendimiento de distintos modelos sin afectar el test set. Si es muy peque√±o, entonces sus evaluaciones seran imprecisas. Si es muy grande, training set ser√° muy peque√±o.

3. Test Set (conjunto de prueba): Se usa solo al final, despu√©s de elegir el mejor modelo, para obtener una estimaci√≥n imparcial del error de generalizaci√≥n.

*Pasos*:

  -Dividir datos en entrenamiento y validacion.
  
  -Entrenar varios modelos con diferentes hiperparametros en el training set (sin validacion).
  
  -Evaluo modelos con validation set.
  
  -Reentreno el modelo selecionado usando el conjunto de entrenamiento completo (incluyendo validacion).
  
  -Prueba el modelo en set test para obtener una vision realista sobre el error de generalizaci√≥n.

**EJ**: Evaluaci√≥n final con el Test Set, probamos este modelo en los 100 estudiantes que nunca ha visto (test set) para medir su verdadera precisi√≥n.

üîπ Si la precisi√≥n en el test set es similar a la del validation set, el modelo generaliza bien.

üîπ Si la precisi√≥n baja mucho, es posible que el modelo haya memorizado los datos de entrenamiento y necesite ajustes.

***

**Cross-validation**: Si usamos solo un conjunto de validaci√≥n (como en holdout validation), podr√≠amos tener suerte o mala suerte con la divisi√≥n de los datos.

*Pasos con K-Fold-Cross-Validation K=5*: **la idea es que cada parte se use como conjunto de validaci√≥n una vez, mientras las otras se usan para entrenar.**

  -Dividimos los datos en 5 partes iguales.
  -Entrenamos el modelo con 4 partes y lo probamos en la restante.
  -Repetimos esto 5 veces, utilizando una parte distinta para probar cada ronda. (Entrenar y validar en cada iteraci√≥n. Registrar m√©tricas.)
  -Promediamos los resultados de las 5 pruebas para obtener una mejor estimaci√≥n del rendimiento real del modelo.

**La validaci√≥n cruzada repetida nos da una mejor medida del rendimiento del modelo al probarlo en muchos conjuntos de validaci√≥n diferentes, pero a cambio aumenta mucho el tiempo de entrenamiento.**

**Por lo tanto, iteras por cada parte, y las restantes las utilizas de entrenamiento.**

Supongamos que tenemos 5000 datos en total.

1Ô∏è‚É£ Dividimos los datos inicialmente en:

  -Training Set (4000 datos) ‚Üí Usado para K-Fold.
  
  -Test Set (1000 datos) ‚Üí Guardado aparte para la evaluaci√≥n final.
  
2Ô∏è‚É£ Aplicamos K-Fold (K=5) en el Training Set (4000 datos)

  -Entrenamos y validamos 5 veces con distintos folds.

  -Calculamos el promedio de precisi√≥n.

  -Elegimos el mejor modelo seg√∫n los resultados de validaci√≥n.
  
3Ô∏è‚É£ Entrenamos el modelo final con los 4000 datos completos

  -Ya no usamos folds.
  
  -El objetivo es que el modelo aproveche toda la informaci√≥n posible.
  
4Ô∏è‚É£ Evaluamos en el Test Set (1000 datos)

  -Ahora usamos los datos de prueba reales que el modelo nunca ha visto.
  
  -Esto nos da la verdadera precisi√≥n del modelo en datos nuevos.

***

**Debemos darnos la posibilidad de siempre preguntarnos si los datos son representativos**

**En este caso, la regla m√°s importante a recordar es que el conjunto de validaci√≥n y el conjunto de prueba deben ser lo m√°s representativos posible de los datos que espera utilizar en producci√≥n**

**Desajuste de los datos**:

EJ: Debemos asegurarnos de que estos conjuntos contengan solo im√°genes tomadas con la app, no im√°genes de internet. Esto nos ayudar√° a medir el rendimiento real del modelo en condiciones reales.

Despu√©s de entrenar con im√°genes de internet, podr√≠amos notar que el modelo tiene mal desempe√±o en el validation set **¬øPor qu√©?**:

  -Modelo ha sobreajustado a las imagenes de internet.
  
  -Las imagenes de internet no se parecen a las de la app.

**Para esto utilizamos Train-Dev set**

*¬øQu√© es el Train-Dev Set y c√≥mo ayuda?*

Imagina que quieres entrenar un modelo de Machine Learning que clasifique im√°genes de perros y gatos.

1Ô∏è‚É£ Los datos disponibles:

  -Descargas 1,000,000 im√°genes de perros y gatos de internet.
  
  -Tomas 10,000 im√°genes de perros y gatos tomadas con la c√°mara del celular, que representan las im√°genes reales que los usuarios tomar√°n en la app.

Conjunto        /      Cantidad      /      Origen

Training Set	  /      990,000       /	    Im√°genes de internet (se usa para entrenar)

Train-Dev Set	  /      10,000        /      Im√°genes de internet (se usa para evaluar si hay overfitting)

Validation Set  /	     5,000         /    	Im√°genes tomadas con el celular (se usa para medir el desempe√±o en datos reales)

Test Set        /      5,000         /      Im√°genes tomadas con el celular (se usa solo para la evaluaci√≥n final)


**Train-Dev Set: Es un subconjunto de im√°genes de internet que NO se usa para entrenar, solo para evaluar si el modelo ha sobreajustado.**

**Validation Set y Test Set: Son im√°genes reales tomadas con celular, ya que representan los datos que el modelo ver√° en producci√≥n.**


üìå Entrenas el modelo con el Training Set (990,000 im√°genes de internet).

üìå Luego, lo eval√∫as en el Train-Dev Set (10,000 im√°genes de internet que no se usaron en el entrenamiento).

üìå Luego, lo eval√∫as en el Validation Set (5,000 im√°genes reales del celular).


Caso 1: El modelo tiene buen desempe√±o en Train-Dev pero mal en Validaci√≥n

Conjunto	                            Precisi√≥n

Train-Dev Set (im√°genes de internet)	90% ‚úÖ

Validation Set (im√°genes del celular)	60% ‚ùå

**El modelo funciona bien en im√°genes de internet, pero mal en im√°genes reales. Hay un desajuste de datos (data mismatch).**


Caso 2: El modelo tiene mal desempe√±o en Train-Dev y en Validaci√≥n

Conjunto	                            Precisi√≥n

Train-Dev Set (im√°genes de internet)	70% ‚ùå

Validation Set (im√°genes del celular)	60% ‚ùå

**El modelo no generaliza bien ni siquiera en im√°genes de internet. Est√° sobreajustando al Training Set.**


***
üìå Una vez que encuentras la mejor versi√≥n del modelo, lo reentrenas con todos los datos de internet + datos reales.

üìå Finalmente, lo pruebas en el Test Set (5,000 im√°genes reales de celular) para obtener su precisi√≥n final.

üìå Train-Dev Set se usa para ver si hay overfitting al entrenamiento.

üìå Si el modelo falla en Train-Dev, hay overfitting.

üìå Si el modelo solo falla en Validaci√≥n, hay desajuste de datos (data mismatch).
